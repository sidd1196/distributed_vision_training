{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Efficient Adaptation and Analysis of Vision Transformers using LoRA"
      ],
      "metadata": {
        "id": "ewAZzlObaczz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "\n",
        "print(\"=== PyTorch Environment Test ===\")\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "    # Test GPU tensor\n",
        "    x = torch.randn(3, 3).cuda()\n",
        "    print(f\"\\nGPU tensor created: {x.device}\")\n",
        "    print(f\"Tensor shape: {x.shape}\")\n",
        "else:\n",
        "    print(\"CUDA not available - using CPU\")\n",
        "    x = torch.randn(3, 3)\n",
        "    print(f\"CPU tensor created: {x.device}\")\n",
        "\n",
        "print(\"\\n✅ PyTorch test completed!\")"
      ],
      "metadata": {
        "id": "OWw0nugHYljv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5781753e-d176-4918-d986-212db18a493d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PyTorch Environment Test ===\n",
            "Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "CUDA version: 12.6\n",
            "Number of GPUs: 1\n",
            "GPU name: NVIDIA A100-SXM4-80GB\n",
            "\n",
            "GPU tensor created: cuda:0\n",
            "Tensor shape: torch.Size([3, 3])\n",
            "\n",
            "✅ PyTorch test completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjqlSFcRPKAh",
        "outputId": "cca1cf44-0298-4c43-89ab-139524b54045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.22.2)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.11.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.42.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msiddpath\u001b[0m (\u001b[33msiddpath-university-of-maryland\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Downloading the data"
      ],
      "metadata": {
        "id": "17dCZxUzMhMD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "770b94b9",
        "outputId": "e94348d5-140e-415e-8d6e-2a1f0294d362"
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load the CIFAR-100 training dataset\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "# Load the CIFAR-100 test dataset\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "print(\"CIFAR-100 dataset imported successfully.\")\n",
        "print(f\"Training set size: {len(trainset)}\")\n",
        "print(f\"Test set size: {len(testset)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:05<00:00, 30.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR-100 dataset imported successfully.\n",
            "Training set size: 50000\n",
            "Test set size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VZywhoZLYll_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Resizing the data for ViT model\n"
      ],
      "metadata": {
        "id": "vmiQ12PxMvRG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6edb525",
        "outputId": "9469118b-a692-4a84-87e2-f87f137c01be"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define transforms for training and validation/testing\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Upsample to ViT resolution\n",
        "    transforms.RandomHorizontalFlip(), # Example data augmentation\n",
        "    transforms.RandomCrop(224, padding=4), # Example data augmentation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # Upsample to ViT resolution\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Apply the transforms to the datasets\n",
        "trainset.transform = train_transform\n",
        "testset.transform = test_transform\n",
        "\n",
        "print(\"Data preparation complete. Transforms applied to datasets.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preparation complete. Transforms applied to datasets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ceO7JH5qYloQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the VIT and freezing the parameters"
      ],
      "metadata": {
        "id": "QGUdLT2ZM1H7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42daad35",
        "outputId": "8ac2af14-f18e-4ed4-ee03-f09fa763ef85"
      },
      "source": [
        "from transformers import ViTForImageClassification\n",
        "\n",
        "# Load a pre-trained Vision Transformer model\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224', num_labels=100, ignore_mismatched_sizes=True)\n",
        "\n",
        "# # Freeze all parameters\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = False # This freezes the parameters\n",
        "\n",
        "# print(\"Pre-trained ViT model loaded and parameters frozen.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([100]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([100, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qd01EMRNYlqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e486f47b"
      },
      "source": [
        "# %pip install peft transformers datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here we decide if we want to train full model or some"
      ],
      "metadata": {
        "id": "hdk8zKbOMxTF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "621f2f8d"
      },
      "source": [
        "# Going for full\n",
        "\n",
        "# from peft import LoraConfig, get_peft_model\n",
        "\n",
        "# # Define LoRA configuration\n",
        "# config = LoraConfig(\n",
        "#     r=16, # Rank of the update matrices.\n",
        "#     lora_alpha=16, # Scaling factor for the LoRA update.\n",
        "#     target_modules=[\"query\", \"value\"], # Modules to apply LoRA to.\n",
        "#     lora_dropout=0.1, # Dropout probability for LoRA layers.\n",
        "#     bias=\"none\", # Bias type.\n",
        "# )\n",
        "\n",
        "# # Get the LoRA-infused model\n",
        "# model = get_peft_model(model, config)\n",
        "\n",
        "# # Print trainable parameters\n",
        "# model.print_trainable_parameters()\n",
        "\n",
        "# print(\"LoRA adapters integrated into the model.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d67efd05",
        "outputId": "d7755864-7f6d-4b13-aa23-b83a30af12d9"
      },
      "source": [
        "# Print the number of trainable parameters\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Number of trainable parameters: {trainable_params}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters: 85875556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model"
      ],
      "metadata": {
        "id": "BYxoz80n3_hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AjEPQofQ3_W-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17a23fae"
      },
      "source": [
        "# You need to reinstall DeepSpeed and force it to compile this special CPU Adam extension.\n",
        "\n",
        "# # # Uninstall the old version first\n",
        "# !pip uninstall deepspeed -y\n",
        "\n",
        "# # Re-install with the build flag for CPUAdam\n",
        "# !DS_BUILD_CPU_ADAM=1 pip install deepspeed\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cqQBFTAwqlTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "459dc0d2"
      },
      "source": [
        "Next, we need to create a DeepSpeed configuration file. This is typically a JSON file that specifies the various optimization settings for DeepSpeed. Here's an example configuration for mixed precision training and ZeRO Stage 2 optimization, which is often used for memory efficiency.\n",
        "\n",
        "You can save this configuration to a file named `deepspeed_config.json`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ae815af",
        "outputId": "b1371a77-ccaa-4019-beea-3fdfbcffd314"
      },
      "source": [
        "%%writefile deepspeed_config.json\n",
        "{\n",
        "    \"fp16\": {\n",
        "        \"enabled\": \"auto\",\n",
        "        \"loss_scale\": 0,\n",
        "        \"loss_scale_window\": 1000\n",
        "    },\n",
        "    \"zero_optimization\": {\n",
        "        \"stage\": 2,\n",
        "        \"offload_optimizer\": {\n",
        "            \"device\": \"cpu\",\n",
        "            \"pin_memory\": true\n",
        "        }\n",
        "    },\n",
        "    \"zero_force_ds_cpu_optimizer\": false,\n",
        "    \"train_batch_size\": 16,\n",
        "    \"train_micro_batch_size_per_gpu\": 16,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"gradient_clipping\": 1.0,\n",
        "    \"steps_per_print\": 200\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deepspeed_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Create the DataLoaders"
      ],
      "metadata": {
        "id": "X0Gsft8sl6yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(trainset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(testset, batch_size=16, shuffle=False)\n",
        "\n",
        "print(\"DataLoaders created.\")"
      ],
      "metadata": {
        "id": "ht7eS4piYl13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6307b33-1296-4cd2-9387-53968a2d7e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoaders created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Enable Gradient Checkpointing"
      ],
      "metadata": {
        "id": "MIEb8JphmELT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable gradient checkpointing\n",
        "model.gradient_checkpointing_enable()\n",
        "print(\"Gradient checkpointing enabled.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pV14uvsLmASg",
        "outputId": "6f434640-10c4-405d-c9bc-566cdd20be95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient checkpointing enabled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Initialize DeepSpeed"
      ],
      "metadata": {
        "id": "NFW9w8YcmQBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install mpi4py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8ZDhNyPmaMs",
        "outputId": "f51fc9d7-34f9-4b36-c0df-bd3adebe3f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpi4py\n",
            "  Downloading mpi4py-4.1.1-cp312-cp312-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (16 kB)\n",
            "Downloading mpi4py-4.1.1-cp312-cp312-manylinux1_x86_64.manylinux_2_5_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpi4py\n",
            "Successfully installed mpi4py-4.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install deepspeed"
      ],
      "metadata": {
        "id": "vzppX2gFQS2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import deepspeed\n",
        "\n",
        "# 1. Manually create the standard PyTorch optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# 2. Initialize DeepSpeed, passing the optimizer you just created\n",
        "model_engine, optimizer, _, _ = deepspeed.initialize(\n",
        "    model=model,\n",
        "    optimizer=optimizer,  # Pass the optimizer here\n",
        "    config_params='deepspeed_config.json'\n",
        ")\n",
        "\n",
        "print(\"DeepSpeed engine initialized with PyTorch AdamW (forced).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UnTnzyjmBBJ",
        "outputId": "0d08b6ca-38fc-4354-afc5-2d5ffb5e9ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepSpeed engine initialized with PyTorch AdamW (forced).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Write the Training Script LoRA-DeepSpeed-T4-Baseline"
      ],
      "metadata": {
        "id": "LBsbc_AqS7G5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import ViTForImageClassification\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import deepspeed\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import warnings\n",
        "import wandb  # <-- 1. IMPORT WANDB\n",
        "import os     # <-- Import OS to get rank\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"--- Initializing Training Script ---\")\n",
        "\n",
        "# --- W&B Setup ---\n",
        "# Set the project name\n",
        "WANDB_PROJECT = \"optimized-vit-periodic-labs\"\n",
        "# Define a name for this specific run\n",
        "WANDB_RUN_NAME = \"LoRA-DeepSpeed-T4-Baseline\"\n",
        "\n",
        "# --- 1. Data Prep ---\n",
        "print(\"Setting up data transformations...\")\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(224, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "print(\"Loading CIFAR-100 dataset...\")\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transform)\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(testset, batch_size=16, shuffle=False, num_workers=2)\n",
        "print(\"DataLoaders created.\")\n",
        "\n",
        "# --- 2. Model Setup ---\n",
        "print(\"Loading pre-trained ViT model...\")\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224', num_labels=100, ignore_mismatched_sizes=True)\n",
        "\n",
        "# Freeze all parameters first\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# --- 3. LoRA Setup ---\n",
        "print(\"Applying LoRA adapters...\")\n",
        "config = LoraConfig(\n",
        "    r=16, lora_alpha=16,\n",
        "    target_modules=[\"query\", \"value\"],\n",
        "    lora_dropout=0.1, bias=\"none\",\n",
        ")\n",
        "model = get_peft_model(model, config)\n",
        "print(\"LoRA adapters applied.\")\n",
        "\n",
        "# --- !! CORRECTED ORDER: Unfreeze classifier AFTER LoRA !! ---\n",
        "print(\"Unfreezing classification head...\")\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "# --- End of Fix ---\n",
        "\n",
        "print(\"New trainable parameters:\")\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# --- 4. Gradient Checkpointing (Task 8) ---\n",
        "print(\"Enabling gradient checkpointing...\")\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "# --- 5. DeepSpeed Initialization (Task 8) ---\n",
        "print(\"Initializing DeepSpeed...\")\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
        "model_engine, optimizer, _, _ = deepspeed.initialize(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    config_params='deepspeed_config.json'\n",
        ")\n",
        "print(\"DeepSpeed engine initialized successfully.\")\n",
        "\n",
        "# --- 6. WANDB INITIALIZATION ---\n",
        "# DeepSpeed provides the rank env var\n",
        "rank = int(os.environ.get('RANK', 0))\n",
        "if rank == 0: # Only initialize W&B on the main process\n",
        "    wandb.init(\n",
        "        project=WANDB_PROJECT,\n",
        "        name=WANDB_RUN_NAME,\n",
        "        config={\n",
        "            \"learning_rate\": 5e-5,\n",
        "            \"epochs\": 3,\n",
        "            \"batch_size\": 16,\n",
        "            \"lora_r\": 16,\n",
        "            \"model\": \"vit-base\",\n",
        "            \"optimization\": \"DeepSpeed ZeRO-Offload + LoRA\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "# --- 7. Training Loop (Task 9) ---\n",
        "device = model_engine.device\n",
        "num_epochs = 3 # Start with 3-5 epochs to test\n",
        "\n",
        "print(f\"--- Starting training for {num_epochs} epochs ---\")\n",
        "for epoch in range(num_epochs):\n",
        "    model_engine.train()\n",
        "    total_loss = 0\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model_engine(inputs, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        model_engine.backward(loss)\n",
        "        model_engine.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # --- 8. LOG TO WANDB (Inside loop) ---\n",
        "        if rank == 0: # Only log from the main process\n",
        "            wandb.log({\"step_loss\": loss.item()})\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"  Epoch {epoch+1}, Step {i}: Loss = {loss.item():.4f}\")\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    print(f\"**Epoch {epoch+1}/{num_epochs} - Avg. Training Loss: {total_loss / len(train_loader):.4f}**\")\n",
        "\n",
        "    # --- 9. LOG TO WANDB (End of epoch) ---\n",
        "    if rank == 0:\n",
        "        wandb.log({\"epoch\": epoch+1, \"avg_train_loss\": avg_train_loss})\n",
        "\n",
        "print(\"--- Training complete ---\")\n",
        "\n",
        "# --- 10. Evaluation (Task 11) ---\n",
        "print(\"--- Starting evaluation ---\")\n",
        "model_engine.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model_engine(inputs)\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"**Final Test Accuracy: {accuracy:.2f}%**\")\n",
        "\n",
        "# --- 11. Confusion Matrix (Task 11) ---\n",
        "print(\"Generating confusion matrix...\")\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix (first 10x10):\")\n",
        "print(cm[:10, :10])\n",
        "\n",
        "# --- 12. LOG FINAL METRICS TO WANDB ---\n",
        "if rank == 0:\n",
        "    wandb.log({\"final_test_accuracy\": accuracy})\n",
        "\n",
        "    # Optional: Log the confusion matrix as a W&B Table\n",
        "    # You can visualize this in the W&B dashboard\n",
        "    class_names = trainset.classes # Get class names from dataset\n",
        "    wandb_cm = wandb.plot.confusion_matrix(\n",
        "        preds=all_preds,\n",
        "        y_true=all_labels,\n",
        "        class_names=class_names\n",
        "    )\n",
        "    wandb.log({\"confusion_matrix\": wandb_cm})\n",
        "\n",
        "    wandb.finish() # Finish the run\n",
        "\n",
        "print(\"--- Run complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgSVKeKMmBDT",
        "outputId": "e3618a59-0789-4977-af11-eb21c08cf271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install libraries for the script, just in case\n",
        "# !pip install deepspeed scikit-learn"
      ],
      "metadata": {
        "id": "8H5AFJ0pmBGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch the training script with DeepSpeed\n",
        "# !deepspeed --num_gpus=1 train.py\n",
        "# We're just adding --master_port 29501 to pick a new, free port\n",
        "!deepspeed --num_gpus=1 --master_port 29501 train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD3rJx22mBIp",
        "outputId": "f7db5649-67e7-4c0c-ed07-d4b1399f400d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-22 23:30:26.124413: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761175826.143434    2809 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761175826.149236    2809 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761175826.163884    2809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761175826.163909    2809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761175826.163912    2809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761175826.163914    2809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "[2025-10-22 23:30:29,188] [WARNING] [runner.py:232:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2025-10-22 23:30:29,189] [INFO] [runner.py:630:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29501 --enable_each_rank_log=None --log_level=info train.py\n",
            "2025-10-22 23:30:36.668617: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761175836.688555    2933 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761175836.694660    2933 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761175836.709374    2933 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761175836.709398    2933 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761175836.709402    2933 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761175836.709407    2933 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "[2025-10-22 23:30:39,729] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.22.3-1+cuda12.5\n",
            "[2025-10-22 23:30:39,729] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.22.3-1\n",
            "[2025-10-22 23:30:39,729] [INFO] [launch.py:155:main] 0 NCCL_VERSION=2.22.3-1\n",
            "[2025-10-22 23:30:39,729] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2025-10-22 23:30:39,729] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.22.3-1+cuda12.5\n",
            "[2025-10-22 23:30:39,729] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2025-10-22 23:30:39,729] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.22.3-1\n",
            "[2025-10-22 23:30:39,729] [INFO] [launch.py:162:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2025-10-22 23:30:39,729] [INFO] [launch.py:168:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2025-10-22 23:30:39,729] [INFO] [launch.py:179:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2025-10-22 23:30:39,729] [INFO] [launch.py:180:main] dist_world_size=1\n",
            "[2025-10-22 23:30:39,729] [INFO] [launch.py:184:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2025-10-22 23:30:39,730] [INFO] [launch.py:272:main] process 3061 spawned with command: ['/usr/bin/python3', '-u', 'train.py', '--local_rank=0']\n",
            "2025-10-22 23:30:44.753231: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761175844.772083    3061 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761175844.777831    3061 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761175844.792210    3061 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761175844.792234    3061 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761175844.792237    3061 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761175844.792239    3061 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "--- Initializing Training Script ---\n",
            "Setting up data transformations...\n",
            "Loading CIFAR-100 dataset...\n",
            "DataLoaders created.\n",
            "Loading pre-trained ViT model...\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([100]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([100, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Applying LoRA adapters...\n",
            "LoRA adapters applied.\n",
            "Unfreezing classification head...\n",
            "New trainable parameters:\n",
            "trainable params: 666,724 || all params: 86,465,380 || trainable%: 0.7711\n",
            "Enabling gradient checkpointing...\n",
            "Initializing DeepSpeed...\n",
            "DeepSpeed engine initialized successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msiddpath\u001b[0m (\u001b[33msiddpath-university-of-maryland\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20251022_233055-7jdae4ye\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mLoRA-DeepSpeed-T4-Baseline\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/optimized-vit-periodic-labs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/optimized-vit-periodic-labs/runs/7jdae4ye\u001b[0m\n",
            "--- Starting training for 3 epochs ---\n",
            "  Epoch 1, Step 0: Loss = 4.8370\n",
            "  Epoch 1, Step 100: Loss = 4.4218\n",
            "  Epoch 1, Step 200: Loss = 3.9209\n",
            "  Epoch 1, Step 300: Loss = 3.8416\n",
            "  Epoch 1, Step 400: Loss = 3.4612\n",
            "  Epoch 1, Step 500: Loss = 2.7358\n",
            "  Epoch 1, Step 600: Loss = 2.7994\n",
            "  Epoch 1, Step 700: Loss = 2.9249\n",
            "  Epoch 1, Step 800: Loss = 2.6899\n",
            "  Epoch 1, Step 900: Loss = 1.9761\n",
            "  Epoch 1, Step 1000: Loss = 2.1980\n",
            "  Epoch 1, Step 1100: Loss = 1.9941\n",
            "  Epoch 1, Step 1200: Loss = 1.5916\n",
            "  Epoch 1, Step 1300: Loss = 1.3764\n",
            "  Epoch 1, Step 1400: Loss = 1.0518\n",
            "  Epoch 1, Step 1500: Loss = 1.4595\n",
            "  Epoch 1, Step 1600: Loss = 0.9278\n",
            "  Epoch 1, Step 1700: Loss = 1.2863\n",
            "  Epoch 1, Step 1800: Loss = 1.0708\n",
            "  Epoch 1, Step 1900: Loss = 0.7781\n",
            "  Epoch 1, Step 2000: Loss = 1.4134\n",
            "  Epoch 1, Step 2100: Loss = 1.0142\n",
            "  Epoch 1, Step 2200: Loss = 1.1748\n",
            "  Epoch 1, Step 2300: Loss = 1.4580\n",
            "  Epoch 1, Step 2400: Loss = 0.6162\n",
            "  Epoch 1, Step 2500: Loss = 0.8687\n",
            "  Epoch 1, Step 2600: Loss = 0.5029\n",
            "  Epoch 1, Step 2700: Loss = 0.8771\n",
            "  Epoch 1, Step 2800: Loss = 0.9992\n",
            "  Epoch 1, Step 2900: Loss = 0.7631\n",
            "  Epoch 1, Step 3000: Loss = 0.9279\n",
            "  Epoch 1, Step 3100: Loss = 0.8468\n",
            "**Epoch 1/3 - Avg. Training Loss: 1.7825**\n",
            "  Epoch 2, Step 0: Loss = 0.7482\n",
            "  Epoch 2, Step 100: Loss = 0.9167\n",
            "  Epoch 2, Step 200: Loss = 0.8443\n",
            "  Epoch 2, Step 300: Loss = 0.9095\n",
            "  Epoch 2, Step 400: Loss = 0.9176\n",
            "  Epoch 2, Step 500: Loss = 1.1597\n",
            "  Epoch 2, Step 600: Loss = 0.7149\n",
            "  Epoch 2, Step 700: Loss = 0.8684\n",
            "  Epoch 2, Step 800: Loss = 0.2810\n",
            "  Epoch 2, Step 900: Loss = 0.9291\n",
            "  Epoch 2, Step 1000: Loss = 0.5585\n",
            "  Epoch 2, Step 1100: Loss = 0.5128\n",
            "  Epoch 2, Step 1200: Loss = 0.6368\n",
            "  Epoch 2, Step 1300: Loss = 0.4114\n",
            "  Epoch 2, Step 1400: Loss = 0.9738\n",
            "  Epoch 2, Step 1500: Loss = 0.1977\n",
            "  Epoch 2, Step 1600: Loss = 1.1684\n",
            "  Epoch 2, Step 1700: Loss = 1.2852\n",
            "  Epoch 2, Step 1800: Loss = 0.5150\n",
            "  Epoch 2, Step 1900: Loss = 0.5867\n",
            "  Epoch 2, Step 2000: Loss = 0.7362\n",
            "  Epoch 2, Step 2100: Loss = 0.7407\n",
            "  Epoch 2, Step 2200: Loss = 0.2283\n",
            "  Epoch 2, Step 2300: Loss = 0.5436\n",
            "  Epoch 2, Step 2400: Loss = 0.8828\n",
            "  Epoch 2, Step 2500: Loss = 0.5589\n",
            "  Epoch 2, Step 2600: Loss = 1.0901\n",
            "  Epoch 2, Step 2700: Loss = 0.4549\n",
            "  Epoch 2, Step 2800: Loss = 0.5585\n",
            "  Epoch 2, Step 2900: Loss = 0.5123\n",
            "  Epoch 2, Step 3000: Loss = 0.1779\n",
            "  Epoch 2, Step 3100: Loss = 0.4142\n",
            "**Epoch 2/3 - Avg. Training Loss: 0.6533**\n",
            "  Epoch 3, Step 0: Loss = 0.8551\n",
            "  Epoch 3, Step 100: Loss = 1.0400\n",
            "  Epoch 3, Step 200: Loss = 0.4261\n",
            "  Epoch 3, Step 300: Loss = 0.5572\n",
            "  Epoch 3, Step 400: Loss = 1.1494\n",
            "  Epoch 3, Step 500: Loss = 0.2709\n",
            "  Epoch 3, Step 600: Loss = 0.7568\n",
            "  Epoch 3, Step 700: Loss = 0.9794\n",
            "  Epoch 3, Step 800: Loss = 0.1863\n",
            "  Epoch 3, Step 900: Loss = 0.3823\n",
            "  Epoch 3, Step 1000: Loss = 1.3950\n",
            "  Epoch 3, Step 1100: Loss = 0.4888\n",
            "  Epoch 3, Step 1200: Loss = 0.4784\n",
            "  Epoch 3, Step 1300: Loss = 0.3658\n",
            "  Epoch 3, Step 1400: Loss = 0.9068\n",
            "  Epoch 3, Step 1500: Loss = 0.5337\n",
            "  Epoch 3, Step 1600: Loss = 0.5126\n",
            "  Epoch 3, Step 1700: Loss = 0.3860\n",
            "  Epoch 3, Step 1800: Loss = 0.9416\n",
            "  Epoch 3, Step 1900: Loss = 0.3365\n",
            "  Epoch 3, Step 2000: Loss = 0.5568\n",
            "  Epoch 3, Step 2100: Loss = 0.6908\n",
            "  Epoch 3, Step 2200: Loss = 1.1846\n",
            "  Epoch 3, Step 2300: Loss = 0.2120\n",
            "  Epoch 3, Step 2400: Loss = 0.4486\n",
            "  Epoch 3, Step 2500: Loss = 0.7735\n",
            "  Epoch 3, Step 2600: Loss = 0.4770\n",
            "  Epoch 3, Step 2700: Loss = 0.3588\n",
            "  Epoch 3, Step 2800: Loss = 0.6545\n",
            "  Epoch 3, Step 2900: Loss = 0.3429\n",
            "  Epoch 3, Step 3000: Loss = 0.7080\n",
            "  Epoch 3, Step 3100: Loss = 0.6993\n",
            "**Epoch 3/3 - Avg. Training Loss: 0.5494**\n",
            "--- Training complete ---\n",
            "--- Starting evaluation ---\n",
            "**Final Test Accuracy: 82.72%**\n",
            "Generating confusion matrix...\n",
            "Confusion Matrix (first 10x10):\n",
            "[[94  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 92  0  1  0  0  0  0  0  0]\n",
            " [ 0  0 77  0  0  3  0  0  0  0]\n",
            " [ 0  0  0 86  3  0  0  0  0  0]\n",
            " [ 0  0  0  1 73  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 95  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 90  0  0  0]\n",
            " [ 0  0  0  0  0  0  2 88  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 91  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 92]]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/confusion_matrix_table_9379_b5d3ba1dfb6b4ce8cb...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/confusion_matrix_table_9379_b5d3ba1dfb6b4ce8cb...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/confusion_matrix_table_9379_b5d3ba1dfb6b4ce8cb...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/confusion_matrix_table_9379_b5d3ba1dfb6b4ce8cb...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/confusion_matrix_table_9379_b5d3ba1dfb6b4ce8cb...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/confusion_matrix_table_9379_b5d3ba1dfb6b4ce8cb...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/confusion_matrix_table_9379_b5d3ba1dfb6b4ce8cb...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/confusion_matrix_table_9379_b5d3ba1dfb6b4ce8cb...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (0.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/confusion_matrix_table_9379_b5d3ba1dfb6b4ce8cb...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (1.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣻\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (1.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣽\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (1.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣾\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (1.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣷\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (1.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣯\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (1.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣟\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (1.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⡿\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (1.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⢿\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (1.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣻\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-7jdae4ye-confusion_matrix_table (1.6s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣽\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      avg_train_loss █▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch ▁▅█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: final_test_accuracy ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step_loss █▇▇▅▄▃▃▃▂▂▂▁▂▂▂▃▂▁▁▁▂▂▁▁▂▂▁▁▂▁▁▁▂▂▂▂▂▁▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      avg_train_loss 0.54945\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: final_test_accuracy 82.72\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step_loss 1.24558\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mLoRA-DeepSpeed-T4-Baseline\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/optimized-vit-periodic-labs/runs/7jdae4ye\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/optimized-vit-periodic-labs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251022_233055-7jdae4ye/logs\u001b[0m\n",
            "--- Run complete ---\n",
            "[rank0]:[W1023 00:04:01.561346453 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
            "[2025-10-23 00:04:04,003] [INFO] [launch.py:367:main] Process 3061 exits successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zzHisU9Zav59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \"LoRA-Only\" baseline training\n"
      ],
      "metadata": {
        "id": "uB6Al2wLZOrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_lora_only.py\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import ViTForImageClassification\n",
        "from peft import LoraConfig, get_peft_model\n",
        "# No deepspeed import needed\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import warnings\n",
        "import wandb  # <-- Import W&B\n",
        "import os\n",
        "import time   # <-- Import time for benchmarking\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"--- Initializing LoRA-Only Training Script ---\")\n",
        "\n",
        "# --- W&B Setup ---\n",
        "WANDB_PROJECT = \"optimized-vit-periodic-labs\"\n",
        "# Give this run a distinct name for comparison\n",
        "WANDB_RUN_NAME = \"LoRA-Only-T4\"\n",
        "\n",
        "# --- Device Setup ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- 1. Data Prep ---\n",
        "print(\"Setting up data transformations...\")\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(224, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "print(\"Loading CIFAR-100 dataset...\")\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transform)\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(testset, batch_size=16, shuffle=False, num_workers=2)\n",
        "print(\"DataLoaders created.\")\n",
        "\n",
        "# --- 2. Model Setup ---\n",
        "print(\"Loading pre-trained ViT model...\")\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224', num_labels=100, ignore_mismatched_sizes=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# --- 3. LoRA Setup ---\n",
        "print(\"Applying LoRA adapters...\")\n",
        "config = LoraConfig(\n",
        "    r=16, lora_alpha=16,\n",
        "    target_modules=[\"query\", \"value\"],\n",
        "    lora_dropout=0.1, bias=\"none\",\n",
        ")\n",
        "model = get_peft_model(model, config)\n",
        "print(\"LoRA adapters applied.\")\n",
        "\n",
        "# --- Unfreeze classifier AFTER LoRA ---\n",
        "print(\"Unfreezing classification head...\")\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "print(\"New trainable parameters:\")\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# --- 4. Gradient Checkpointing ---\n",
        "print(\"Enabling gradient checkpointing...\")\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "# --- Move model to GPU ---\n",
        "model.to(device)\n",
        "print(f\"Model moved to {device}.\")\n",
        "\n",
        "# --- 5. Standard PyTorch Optimizer (NO DEEPSPEED) ---\n",
        "print(\"Initializing standard PyTorch AdamW optimizer...\")\n",
        "# Only parameters requiring gradients will be optimized\n",
        "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=5e-5)\n",
        "\n",
        "# --- 6. WANDB INITIALIZATION ---\n",
        "wandb.init(\n",
        "    project=WANDB_PROJECT,\n",
        "    name=WANDB_RUN_NAME,\n",
        "    config={\n",
        "        \"learning_rate\": 5e-5,\n",
        "        \"epochs\": 3,\n",
        "        \"batch_size\": 16,\n",
        "        \"lora_r\": 16,\n",
        "        \"model\": \"vit-base\",\n",
        "        \"optimization\": \"LoRA + Gradient Checkpointing (No DeepSpeed)\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# --- 7. Standard Training Loop (NO DEEPSPEED) ---\n",
        "num_epochs = 3\n",
        "print(f\"--- Starting training for {num_epochs} epochs ---\")\n",
        "start_time = time.time() # Start timer\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    epoch_start_time = time.time() # Timer for epoch\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Standard forward pass\n",
        "        outputs = model(inputs, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Standard backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Standard optimizer step\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad() # Clear gradients for next step\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Log step loss to W&B\n",
        "        wandb.log({\"step_loss\": loss.item()})\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"  Epoch {epoch+1}, Step {i}: Loss = {loss.item():.4f}\")\n",
        "\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_duration = epoch_end_time - epoch_start_time\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    print(f\"**Epoch {epoch+1}/{num_epochs} - Avg. Training Loss: {avg_train_loss:.4f} (Duration: {epoch_duration:.2f}s)**\")\n",
        "\n",
        "    # Log epoch metrics to W&B\n",
        "    wandb.log({\"epoch\": epoch+1, \"avg_train_loss\": avg_train_loss, \"epoch_duration_sec\": epoch_duration})\n",
        "\n",
        "end_time = time.time()\n",
        "total_training_time = end_time - start_time\n",
        "print(f\"--- Training complete in {total_training_time:.2f} seconds ---\")\n",
        "\n",
        "# --- 8. Evaluation ---\n",
        "print(\"--- Starting evaluation ---\")\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Use the standard model for inference\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"**Final Test Accuracy: {accuracy:.2f}%**\")\n",
        "\n",
        "# --- 9. Confusion Matrix ---\n",
        "print(\"Generating confusion matrix...\")\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix (first 10x10):\")\n",
        "print(cm[:10, :10])\n",
        "\n",
        "# --- 10. LOG FINAL METRICS TO WANDB ---\n",
        "wandb.log({\n",
        "    \"final_test_accuracy\": accuracy,\n",
        "    \"total_training_time_sec\": total_training_time\n",
        "})\n",
        "\n",
        "# Log confusion matrix plot\n",
        "class_names = trainset.classes\n",
        "wandb_cm = wandb.plot.confusion_matrix(\n",
        "    preds=all_preds, y_true=all_labels, class_names=class_names\n",
        ")\n",
        "wandb.log({\"confusion_matrix\": wandb_cm})\n",
        "\n",
        "wandb.finish() # Finish the run\n",
        "\n",
        "print(\"--- Run complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0HqTAtkZTxE",
        "outputId": "35d0a2c5-a197-4b8d-bf7a-41109e3ff531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train_lora_only.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_lora_only.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xn4PD-AZcTv",
        "outputId": "61e1c8a9-a3fb-4e8b-ca1a-1bc9c9f922bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-23 00:09:20.234732: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761178160.256259   12648 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761178160.262536   12648 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761178160.279651   12648 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761178160.279680   12648 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761178160.279686   12648 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761178160.279690   12648 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "--- Initializing LoRA-Only Training Script ---\n",
            "Using device: cuda\n",
            "Setting up data transformations...\n",
            "Loading CIFAR-100 dataset...\n",
            "DataLoaders created.\n",
            "Loading pre-trained ViT model...\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([100]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([100, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Applying LoRA adapters...\n",
            "LoRA adapters applied.\n",
            "Unfreezing classification head...\n",
            "New trainable parameters:\n",
            "trainable params: 666,724 || all params: 86,465,380 || trainable%: 0.7711\n",
            "Enabling gradient checkpointing...\n",
            "Model moved to cuda.\n",
            "Initializing standard PyTorch AdamW optimizer...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msiddpath\u001b[0m (\u001b[33msiddpath-university-of-maryland\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20251023_000927-dzxxq0f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mLoRA-Only-T4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/optimized-vit-periodic-labs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/optimized-vit-periodic-labs/runs/dzxxq0f6\u001b[0m\n",
            "--- Starting training for 3 epochs ---\n",
            "  Epoch 1, Step 0: Loss = 4.8273\n",
            "  Epoch 1, Step 100: Loss = 4.4363\n",
            "  Epoch 1, Step 200: Loss = 4.2476\n",
            "  Epoch 1, Step 300: Loss = 3.7281\n",
            "  Epoch 1, Step 400: Loss = 3.5762\n",
            "  Epoch 1, Step 500: Loss = 3.3310\n",
            "  Epoch 1, Step 600: Loss = 3.0358\n",
            "  Epoch 1, Step 700: Loss = 2.8571\n",
            "  Epoch 1, Step 800: Loss = 2.3628\n",
            "  Epoch 1, Step 900: Loss = 2.3879\n",
            "  Epoch 1, Step 1000: Loss = 1.8496\n",
            "  Epoch 1, Step 1100: Loss = 1.8247\n",
            "  Epoch 1, Step 1200: Loss = 1.9504\n",
            "  Epoch 1, Step 1300: Loss = 1.8242\n",
            "  Epoch 1, Step 1400: Loss = 1.9610\n",
            "  Epoch 1, Step 1500: Loss = 1.2518\n",
            "  Epoch 1, Step 1600: Loss = 1.3960\n",
            "  Epoch 1, Step 1700: Loss = 1.2765\n",
            "  Epoch 1, Step 1800: Loss = 1.5845\n",
            "  Epoch 1, Step 1900: Loss = 1.2185\n",
            "  Epoch 1, Step 2000: Loss = 0.8245\n",
            "  Epoch 1, Step 2100: Loss = 0.8120\n",
            "  Epoch 1, Step 2200: Loss = 1.3994\n",
            "  Epoch 1, Step 2300: Loss = 1.3974\n",
            "  Epoch 1, Step 2400: Loss = 1.1957\n",
            "  Epoch 1, Step 2500: Loss = 0.5878\n",
            "  Epoch 1, Step 2600: Loss = 0.9835\n",
            "  Epoch 1, Step 2700: Loss = 0.9536\n",
            "  Epoch 1, Step 2800: Loss = 1.3320\n",
            "  Epoch 1, Step 2900: Loss = 0.6909\n",
            "  Epoch 1, Step 3000: Loss = 0.9019\n",
            "  Epoch 1, Step 3100: Loss = 0.8841\n",
            "**Epoch 1/3 - Avg. Training Loss: 1.8512 (Duration: 604.03s)**\n",
            "  Epoch 2, Step 0: Loss = 0.4747\n",
            "  Epoch 2, Step 100: Loss = 0.5007\n",
            "  Epoch 2, Step 200: Loss = 1.0707\n",
            "  Epoch 2, Step 300: Loss = 0.4658\n",
            "  Epoch 2, Step 400: Loss = 0.8258\n",
            "  Epoch 2, Step 500: Loss = 0.3669\n",
            "  Epoch 2, Step 600: Loss = 0.5491\n",
            "  Epoch 2, Step 700: Loss = 0.5177\n",
            "  Epoch 2, Step 800: Loss = 1.1419\n",
            "  Epoch 2, Step 900: Loss = 0.5217\n",
            "  Epoch 2, Step 1000: Loss = 0.2163\n",
            "  Epoch 2, Step 1100: Loss = 0.9466\n",
            "  Epoch 2, Step 1200: Loss = 0.5339\n",
            "  Epoch 2, Step 1300: Loss = 0.4815\n",
            "  Epoch 2, Step 1400: Loss = 0.3690\n",
            "  Epoch 2, Step 1500: Loss = 0.6370\n",
            "  Epoch 2, Step 1600: Loss = 0.3882\n",
            "  Epoch 2, Step 1700: Loss = 0.6700\n",
            "  Epoch 2, Step 1800: Loss = 0.2686\n",
            "  Epoch 2, Step 1900: Loss = 0.7152\n",
            "  Epoch 2, Step 2000: Loss = 0.5982\n",
            "  Epoch 2, Step 2100: Loss = 0.8754\n",
            "  Epoch 2, Step 2200: Loss = 0.4385\n",
            "  Epoch 2, Step 2300: Loss = 1.7735\n",
            "  Epoch 2, Step 2400: Loss = 0.6197\n",
            "  Epoch 2, Step 2500: Loss = 0.7447\n",
            "  Epoch 2, Step 2600: Loss = 1.2494\n",
            "  Epoch 2, Step 2700: Loss = 0.5499\n",
            "  Epoch 2, Step 2800: Loss = 0.4087\n",
            "  Epoch 2, Step 2900: Loss = 0.4299\n",
            "  Epoch 2, Step 3000: Loss = 0.7105\n",
            "  Epoch 2, Step 3100: Loss = 0.9091\n",
            "**Epoch 2/3 - Avg. Training Loss: 0.6938 (Duration: 617.90s)**\n",
            "  Epoch 3, Step 0: Loss = 0.5831\n",
            "  Epoch 3, Step 100: Loss = 0.3847\n",
            "  Epoch 3, Step 200: Loss = 1.0545\n",
            "  Epoch 3, Step 300: Loss = 0.6860\n",
            "  Epoch 3, Step 400: Loss = 1.0053\n",
            "  Epoch 3, Step 500: Loss = 0.7798\n",
            "  Epoch 3, Step 600: Loss = 0.4061\n",
            "  Epoch 3, Step 700: Loss = 0.6497\n",
            "  Epoch 3, Step 800: Loss = 0.2903\n",
            "  Epoch 3, Step 900: Loss = 0.7511\n",
            "  Epoch 3, Step 1000: Loss = 0.0936\n",
            "  Epoch 3, Step 1100: Loss = 0.5207\n",
            "  Epoch 3, Step 1200: Loss = 0.8879\n",
            "  Epoch 3, Step 1300: Loss = 0.4527\n",
            "  Epoch 3, Step 1400: Loss = 0.6667\n",
            "  Epoch 3, Step 1500: Loss = 1.0487\n",
            "  Epoch 3, Step 1600: Loss = 0.5340\n",
            "  Epoch 3, Step 1700: Loss = 0.3291\n",
            "  Epoch 3, Step 1800: Loss = 0.3450\n",
            "  Epoch 3, Step 1900: Loss = 0.1969\n",
            "  Epoch 3, Step 2000: Loss = 0.2307\n",
            "  Epoch 3, Step 2100: Loss = 0.5237\n",
            "  Epoch 3, Step 2200: Loss = 1.3051\n",
            "  Epoch 3, Step 2300: Loss = 0.4550\n",
            "  Epoch 3, Step 2400: Loss = 0.5218\n",
            "  Epoch 3, Step 2500: Loss = 0.6207\n",
            "  Epoch 3, Step 2600: Loss = 0.2114\n",
            "  Epoch 3, Step 2700: Loss = 0.4549\n",
            "  Epoch 3, Step 2800: Loss = 0.1863\n",
            "  Epoch 3, Step 2900: Loss = 0.6588\n",
            "  Epoch 3, Step 3000: Loss = 0.6043\n",
            "  Epoch 3, Step 3100: Loss = 0.3132\n",
            "**Epoch 3/3 - Avg. Training Loss: 0.5681 (Duration: 618.89s)**\n",
            "--- Training complete in 1840.83 seconds ---\n",
            "--- Starting evaluation ---\n",
            "**Final Test Accuracy: 82.93%**\n",
            "Generating confusion matrix...\n",
            "Confusion Matrix (first 10x10):\n",
            "[[92  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 93  0  1  0  0  0  0  0  0]\n",
            " [ 0  0 81  0  0  3  0  0  0  0]\n",
            " [ 0  0  0 83  3  0  0  0  0  0]\n",
            " [ 0  0  0  1 74  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 96  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 88  2  0  0]\n",
            " [ 0  0  0  0  0  0  1 91  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 90  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 91]]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/confusion_matrix_table_9379_fdcc1e5632148d1661...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading history steps 9378-9378, summary, console lines 102-114 (0...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading media/table/confusion_matrix_table_9379_fdcc1e5632148d1661...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading history steps 9378-9378, summary, console lines 102-114 (0...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading media/table/confusion_matrix_table_9379_fdcc1e5632148d1661...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading history steps 9378-9378, summary, console lines 102-114 (0...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading media/table/confusion_matrix_table_9379_fdcc1e5632148d1661...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading history steps 9378-9378, summary, console lines 102-114 (0...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading media/table/confusion_matrix_table_9379_fdcc1e5632148d1661...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading history steps 9378-9378, summary, console lines 102-114 (0...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading media/table/confusion_matrix_table_9379_fdcc1e5632148d1661...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading history steps 9378-9378, summary, console lines 102-114 (0...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading media/table/confusion_matrix_table_9379_fdcc1e5632148d1661...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading history steps 9378-9378, summary, console lines 102-114 (0...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading media/table/confusion_matrix_table_9379_fdcc1e5632148d1661...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading history steps 9378-9378, summary, console lines 102-114 (0...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (1.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading media/table/confusion_matrix_table_9379_fdcc1e5632148d1661...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading history steps 9378-9378, summary, console lines 102-114 (0...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (1.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣻\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (1.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣽\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (1.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣾\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (1.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣷\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (1.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣯\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (1.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣟\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (1.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⡿\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (1.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⢿\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (1.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣻\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run-dzxxq0f6-confusion_matrix_table (1.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣽\u001b[0m confusion_matrix_table.table.json 269.2KB/269.2KB (0.9s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m Finishing up...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          avg_train_loss █▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   epoch ▁▅█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch_duration_sec ▁██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     final_test_accuracy ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               step_loss ██▄▄▃▃▃▂▃▂▂▂▁▁▂▂▂▁▁▁▂▁▁▂▁▁▂▂▂▂▁▁▁▂▁▂▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: total_training_time_sec ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          avg_train_loss 0.5681\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   epoch 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch_duration_sec 618.8889\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     final_test_accuracy 82.93\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               step_loss 0.50452\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: total_training_time_sec 1840.82731\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mLoRA-Only-T4\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/optimized-vit-periodic-labs/runs/dzxxq0f6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/optimized-vit-periodic-labs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251023_000927-dzxxq0f6/logs\u001b[0m\n",
            "--- Run complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LNPoEyLIZfVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# These code snippets are for A100 specially"
      ],
      "metadata": {
        "id": "-B1_-aYK2KQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deepspeed_config_A100_bs64.json\n",
        "{\n",
        "    \"bf16\": {\n",
        "        \"enabled\": true  // Use BFloat16 for A100 performance\n",
        "    },\n",
        "    \"zero_optimization\": {\n",
        "        \"stage\": 2,\n",
        "        \"offload_optimizer\": {\n",
        "            \"device\": \"cpu\", // Still offload optimizer to save VRAM, even with 80GB\n",
        "            \"pin_memory\": true\n",
        "        }\n",
        "    },\n",
        "    \"zero_force_ds_cpu_optimizer\": false, // Use fallback AdamW if DeepSpeedCPUAdam isn't built\n",
        "    \"gradient_accumulation_steps\": 1,     // Accumulate gradients once\n",
        "    \"gradient_clipping\": 1.0,\n",
        "    \"train_batch_size\": 64,               // Target effective batch size\n",
        "    \"train_micro_batch_size_per_gpu\": 64, // Process 64 samples at once per GPU\n",
        "    \"steps_per_print\": 100                // Log more frequently\n",
        "}"
      ],
      "metadata": {
        "id": "YpguPCN1Kqix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c79e3809-f5cd-4251-a3bd-8b00196c2682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deepspeed_config_A100_bs64.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3rCteDu9KqlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Script for Standard Full Fine-Tune (No DeepSpeed - A100, BS=64)"
      ],
      "metadata": {
        "id": "xEZCI7Qy2krh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_standard_full_A100_bs64.py\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import ViTForImageClassification\n",
        "import warnings\n",
        "import wandb\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "print(\"--- Initializing STANDARD FULL-TUNE Script (A100 BS=64) ---\")\n",
        "\n",
        "# --- W&B Setup ---\n",
        "WANDB_PROJECT = \"optimized-vit-periodic-labs\"\n",
        "WANDB_RUN_NAME = \"Standard-Full-Tune-bs64-GC-fp32-A100\" # Larger batch, GC, FP32\n",
        "\n",
        "# --- Device Setup ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- 1. Data Prep ---\n",
        "print(\"Setting up data transformations...\")\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(224, padding=4), transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "print(\"Loading CIFAR-100 dataset...\")\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transform)\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "# --- Use LARGER BATCH SIZE ---\n",
        "MICRO_BATCH_SIZE = 64\n",
        "train_loader = DataLoader(trainset, batch_size=MICRO_BATCH_SIZE, shuffle=True, num_workers=4) # Increased workers\n",
        "test_loader = DataLoader(testset, batch_size=MICRO_BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "print(f\"DataLoaders created with micro_batch_size={MICRO_BATCH_SIZE}.\")\n",
        "\n",
        "# --- 2. Model Setup (NO FREEZING) ---\n",
        "print(\"Loading pre-trained ViT model for full fine-tuning...\")\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224', num_labels=100, ignore_mismatched_sizes=True)\n",
        "\n",
        "# --- Enable Gradient Checkpointing (Safety for BS=64) ---\n",
        "print(\"Enabling gradient checkpointing...\")\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "model.to(device)\n",
        "print(f\"Model moved to {device}.\")\n",
        "\n",
        "# --- 3. Standard PyTorch Optimizer ---\n",
        "print(\"Initializing standard PyTorch AdamW optimizer...\")\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
        "print(f\"Optimizer created. Training {sum(p.numel() for p in model.parameters() if p.requires_grad):,} parameters.\")\n",
        "\n",
        "# --- 4. WANDB INITIALIZATION ---\n",
        "wandb.init(\n",
        "    project=WANDB_PROJECT,\n",
        "    name=WANDB_RUN_NAME,\n",
        "    config={ \"learning_rate\": 5e-5, \"epochs\": 1, \"batch_size\": MICRO_BATCH_SIZE, \"model\": \"vit-base\", \"optimization\": \"Standard Full-Tune (bs=64 + GC + FP32)\"}\n",
        ")\n",
        "\n",
        "# --- 5. Standard Training Loop ---\n",
        "num_epochs = 1\n",
        "print(f\"--- Starting training for {num_epochs} epoch ---\")\n",
        "start_time = time.time()\n",
        "\n",
        "model.train()\n",
        "total_loss = 0\n",
        "epoch_start_time = time.time()\n",
        "# No GradScaler needed for FP32\n",
        "\n",
        "for i, batch in enumerate(train_loader):\n",
        "    inputs, labels = batch\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(inputs, labels=labels)\n",
        "    loss = outputs.loss\n",
        "\n",
        "    loss.backward() # Standard backward, handles GC recomputation\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    wandb.log({\"step_loss\": loss.item()})\n",
        "\n",
        "    if i % 50 == 0: # Print more often with larger batch size\n",
        "        print(f\"  Epoch 1, Step {i}: Loss = {loss.item():.4f}\")\n",
        "\n",
        "epoch_end_time = time.time()\n",
        "epoch_duration = epoch_end_time - epoch_start_time\n",
        "avg_train_loss = total_loss / len(train_loader)\n",
        "print(f\"**Epoch 1/{num_epochs} - Avg. Training Loss: {avg_train_loss:.4f} (Duration: {epoch_duration:.2f}s)**\")\n",
        "wandb.log({\"epoch\": 1, \"avg_train_loss\": avg_train_loss, \"epoch_duration_sec\": epoch_duration})\n",
        "\n",
        "end_time = time.time()\n",
        "total_training_time = end_time - start_time\n",
        "print(f\"--- Training complete in {total_training_time:.2f} seconds ---\")\n",
        "\n",
        "wandb.log({\"total_training_time_sec\": total_training_time})\n",
        "wandb.finish()\n",
        "print(\"--- Run complete ---\")"
      ],
      "metadata": {
        "id": "96vZr6BJKqnK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeb14b93-b3fd-43ea-ad87-a6173de1083b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train_standard_full_A100_bs64.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mt88h9CcKqpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hUXs3SmnKqq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Script for DeepSpeed Full Fine-Tune (A100 Optimized, BS=64)"
      ],
      "metadata": {
        "id": "UYUeC1cw2rox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_deepspeed_full_A100_bs64.py\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import ViTForImageClassification\n",
        "# No peft import needed\n",
        "import deepspeed\n",
        "import warnings\n",
        "import wandb\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "print(\"--- Initializing DEEPSPEED FULL-TUNE Script (A100 BS=64 BF16) ---\")\n",
        "\n",
        "# --- W&B Setup ---\n",
        "WANDB_PROJECT = \"optimized-vit-periodic-labs\"\n",
        "WANDB_RUN_NAME = \"DeepSpeed-Full-Tune-bs64-bf16-A100\" # Updated name\n",
        "\n",
        "# --- 1. Data Prep ---\n",
        "print(\"Setting up data transformations...\")\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(224, padding=4), transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "print(\"Loading CIFAR-100 dataset...\")\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transform)\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "# --- Use LARGER Batch Size ---\n",
        "MICRO_BATCH_SIZE = 64 # Match config file\n",
        "train_loader = DataLoader(trainset, batch_size=MICRO_BATCH_SIZE, shuffle=True, num_workers=4) # Increased workers\n",
        "test_loader = DataLoader(testset, batch_size=MICRO_BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "print(f\"DataLoaders created with micro_batch_size={MICRO_BATCH_SIZE}.\")\n",
        "\n",
        "# --- 2. Model Setup (NO FREEZING) ---\n",
        "print(\"Loading pre-trained ViT model for full fine-tuning...\")\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224', num_labels=100, ignore_mismatched_sizes=True)\n",
        "# --- NO Gradient Checkpointing needed with BF16/DeepSpeed on 80GB ---\n",
        "print(\"Gradient Checkpointing NOT enabled for this run.\")\n",
        "\n",
        "# --- 3. DeepSpeed Initialization ---\n",
        "print(\"Initializing DeepSpeed...\")\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5) # Using fallback\n",
        "model_engine, optimizer, _, _ = deepspeed.initialize(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    config_params='deepspeed_config_A100_bs64.json' # Use the NEW config file\n",
        ")\n",
        "print(f\"DeepSpeed engine initialized. Training {sum(p.numel() for p in model_engine.module.parameters() if p.requires_grad):,} parameters.\")\n",
        "\n",
        "\n",
        "# --- 4. WANDB INITIALIZATION ---\n",
        "rank = int(os.environ.get('RANK', 0))\n",
        "if rank == 0:\n",
        "    wandb.init(\n",
        "        project=WANDB_PROJECT,\n",
        "        name=WANDB_RUN_NAME,\n",
        "        config={ \"learning_rate\": 5e-5, \"epochs\": 1, \"batch_size\": MICRO_BATCH_SIZE, \"model\": \"vit-base\", \"precision\": \"bf16\", \"optimization\": \"DeepSpeed Full-Tune (bs=64 + bf16 + ZeRO2-Offload)\"}\n",
        "    )\n",
        "\n",
        "# --- 5. DeepSpeed Training Loop ---\n",
        "device = model_engine.device\n",
        "num_epochs = 1\n",
        "print(f\"--- Starting training for {num_epochs} epoch ---\")\n",
        "start_time = time.time()\n",
        "\n",
        "model_engine.train()\n",
        "total_loss = 0\n",
        "epoch_start_time = time.time()\n",
        "for i, batch in enumerate(train_loader):\n",
        "    inputs, labels = batch\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model_engine(inputs, labels=labels)\n",
        "    loss = outputs.loss\n",
        "\n",
        "    model_engine.backward(loss)\n",
        "    model_engine.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    if rank == 0:\n",
        "        wandb.log({\"step_loss\": loss.item()})\n",
        "\n",
        "    if i % 50 == 0: # Print more often\n",
        "        print(f\"  Epoch 1, Step {i}: Loss = {loss.item():.4f}\")\n",
        "\n",
        "epoch_end_time = time.time()\n",
        "epoch_duration = epoch_end_time - epoch_start_time\n",
        "avg_train_loss = total_loss / len(train_loader)\n",
        "print(f\"**Epoch 1/{num_epochs} - Avg. Training Loss: {avg_train_loss:.4f} (Duration: {epoch_duration:.2f}s)**\")\n",
        "\n",
        "if rank == 0:\n",
        "    wandb.log({\"epoch\": 1, \"avg_train_loss\": avg_train_loss, \"epoch_duration_sec\": epoch_duration})\n",
        "\n",
        "end_time = time.time()\n",
        "total_training_time = end_time - start_time\n",
        "print(f\"--- Training complete in {total_training_time:.2f} seconds ---\")\n",
        "\n",
        "if rank == 0:\n",
        "    wandb.log({\"total_training_time_sec\": total_training_time})\n",
        "    wandb.finish()\n",
        "print(\"--- Run complete ---\")"
      ],
      "metadata": {
        "id": "5fm0hAs9Kqs8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc6c507-6a57-407d-96b7-d2a0b6ba6aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train_deepspeed_full_A100_bs64.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fYzZfXc1Kquu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9tNXczFQKqwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Runnning the standard script"
      ],
      "metadata": {
        "id": "rnziRqmP5p1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_standard_full_A100_bs64.py"
      ],
      "metadata": {
        "id": "GJ3E1VS3Kqya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9f2cea4-46c7-4fc5-9322-f3cfeae715c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-24 20:27:25.449833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761337645.471274   11394 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761337645.477765   11394 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761337645.494238   11394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761337645.494269   11394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761337645.494272   11394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761337645.494274   11394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "--- Initializing STANDARD FULL-TUNE Script (A100 BS=64) ---\n",
            "Using device: cuda\n",
            "Setting up data transformations...\n",
            "Loading CIFAR-100 dataset...\n",
            "DataLoaders created with micro_batch_size=64.\n",
            "Loading pre-trained ViT model for full fine-tuning...\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([100]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([100, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Enabling gradient checkpointing...\n",
            "Model moved to cuda.\n",
            "Initializing standard PyTorch AdamW optimizer...\n",
            "Optimizer created. Training 85,875,556 parameters.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msiddpath\u001b[0m (\u001b[33msiddpath-university-of-maryland\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m setting up run ztbyj7p8 (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20251024_202733-ztbyj7p8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mStandard-Full-Tune-bs64-GC-fp32-A100\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/optimized-vit-periodic-labs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/optimized-vit-periodic-labs/runs/ztbyj7p8\u001b[0m\n",
            "--- Starting training for 1 epoch ---\n",
            "  Epoch 1, Step 0: Loss = 4.7510\n",
            "  Epoch 1, Step 50: Loss = 3.5171\n",
            "  Epoch 1, Step 100: Loss = 2.1105\n",
            "  Epoch 1, Step 150: Loss = 1.0628\n",
            "  Epoch 1, Step 200: Loss = 0.9352\n",
            "  Epoch 1, Step 250: Loss = 0.8482\n",
            "  Epoch 1, Step 300: Loss = 0.8311\n",
            "  Epoch 1, Step 350: Loss = 0.5511\n",
            "  Epoch 1, Step 400: Loss = 0.6172\n",
            "  Epoch 1, Step 450: Loss = 0.4994\n",
            "  Epoch 1, Step 500: Loss = 0.4237\n",
            "  Epoch 1, Step 550: Loss = 0.3349\n",
            "  Epoch 1, Step 600: Loss = 0.4324\n",
            "  Epoch 1, Step 650: Loss = 0.4161\n",
            "  Epoch 1, Step 700: Loss = 0.4469\n",
            "  Epoch 1, Step 750: Loss = 0.4469\n",
            "**Epoch 1/1 - Avg. Training Loss: 0.9541 (Duration: 431.16s)**\n",
            "--- Training complete in 431.16 seconds ---\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading history steps 761-783, summary, console lines 17-18 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          avg_train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   epoch ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch_duration_sec ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               step_loss █▇▇▇▆▃▃▃▂▂▂▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: total_training_time_sec ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          avg_train_loss 0.95411\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   epoch 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch_duration_sec 431.15988\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               step_loss 0.3454\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: total_training_time_sec 431.16176\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mStandard-Full-Tune-bs64-GC-fp32-A100\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/optimized-vit-periodic-labs/runs/ztbyj7p8\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/optimized-vit-periodic-labs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251024_202733-ztbyj7p8/logs\u001b[0m\n",
            "--- Run complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the DeepSpeed script"
      ],
      "metadata": {
        "id": "XZKBkSDa5zeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch DeepSpeed using a different port\n",
        "!deepspeed --num_gpus=1 --master_port 29501 train_deepspeed_full_A100_bs64.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6Bf5ApW5y3B",
        "outputId": "1b5163de-2456-4361-fa7b-d5e9647650ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-24 20:38:03.573806: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761338283.594997   14481 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761338283.601502   14481 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761338283.617949   14481 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761338283.617978   14481 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761338283.617981   14481 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761338283.617983   14481 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "[2025-10-24 20:38:06,854] [WARNING] [runner.py:232:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2025-10-24 20:38:06,854] [INFO] [runner.py:630:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29501 --enable_each_rank_log=None --log_level=info train_deepspeed_full_A100_bs64.py\n",
            "2025-10-24 20:38:14.970807: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761338294.996077   14635 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761338295.002450   14635 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761338295.018044   14635 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761338295.018071   14635 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761338295.018074   14635 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761338295.018076   14635 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "[2025-10-24 20:38:18,276] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.22.3-1+cuda12.5\n",
            "[2025-10-24 20:38:18,277] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.22.3-1\n",
            "[2025-10-24 20:38:18,277] [INFO] [launch.py:155:main] 0 NCCL_VERSION=2.22.3-1\n",
            "[2025-10-24 20:38:18,277] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\n",
            "[2025-10-24 20:38:18,277] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.22.3-1+cuda12.5\n",
            "[2025-10-24 20:38:18,277] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\n",
            "[2025-10-24 20:38:18,277] [INFO] [launch.py:155:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.22.3-1\n",
            "[2025-10-24 20:38:18,277] [INFO] [launch.py:162:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2025-10-24 20:38:18,277] [INFO] [launch.py:168:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2025-10-24 20:38:18,277] [INFO] [launch.py:179:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2025-10-24 20:38:18,277] [INFO] [launch.py:180:main] dist_world_size=1\n",
            "[2025-10-24 20:38:18,277] [INFO] [launch.py:184:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2025-10-24 20:38:18,277] [INFO] [launch.py:272:main] process 14795 spawned with command: ['/usr/bin/python3', '-u', 'train_deepspeed_full_A100_bs64.py', '--local_rank=0']\n",
            "2025-10-24 20:38:23.812247: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761338303.832892   14795 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761338303.839198   14795 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761338303.854673   14795 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761338303.854699   14795 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761338303.854702   14795 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761338303.854704   14795 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "--- Initializing DEEPSPEED FULL-TUNE Script (A100 BS=64 BF16) ---\n",
            "Setting up data transformations...\n",
            "Loading CIFAR-100 dataset...\n",
            "DataLoaders created with micro_batch_size=64.\n",
            "Loading pre-trained ViT model for full fine-tuning...\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([100]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([100, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Gradient Checkpointing NOT enabled for this run.\n",
            "Initializing DeepSpeed...\n",
            "DeepSpeed engine initialized. Training 85,875,556 parameters.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msiddpath\u001b[0m (\u001b[33msiddpath-university-of-maryland\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m setting up run qmgqttkv (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20251024_203835-qmgqttkv\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mDeepSpeed-Full-Tune-bs64-bf16-A100\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/optimized-vit-periodic-labs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/optimized-vit-periodic-labs/runs/qmgqttkv\u001b[0m\n",
            "--- Starting training for 1 epoch ---\n",
            "  Epoch 1, Step 0: Loss = 4.6875\n",
            "  Epoch 1, Step 50: Loss = 3.3438\n",
            "  Epoch 1, Step 100: Loss = 2.0469\n",
            "  Epoch 1, Step 150: Loss = 0.8672\n",
            "  Epoch 1, Step 200: Loss = 0.7617\n",
            "  Epoch 1, Step 250: Loss = 0.5078\n",
            "  Epoch 1, Step 300: Loss = 0.6406\n",
            "  Epoch 1, Step 350: Loss = 0.2949\n",
            "  Epoch 1, Step 400: Loss = 0.2754\n",
            "  Epoch 1, Step 450: Loss = 0.4258\n",
            "  Epoch 1, Step 500: Loss = 0.3457\n",
            "  Epoch 1, Step 550: Loss = 0.2197\n",
            "  Epoch 1, Step 600: Loss = 0.2559\n",
            "  Epoch 1, Step 650: Loss = 0.5625\n",
            "  Epoch 1, Step 700: Loss = 0.2578\n",
            "  Epoch 1, Step 750: Loss = 0.2617\n",
            "**Epoch 1/1 - Avg. Training Loss: 0.9024 (Duration: 289.48s)**\n",
            "--- Training complete in 289.48 seconds ---\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading history steps 770-783, summary, console lines 17-18 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          avg_train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   epoch ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch_duration_sec ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               step_loss █▆▆▆▆▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▂▁▁▁▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: total_training_time_sec ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          avg_train_loss 0.90242\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   epoch 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch_duration_sec 289.47668\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               step_loss 0.70703\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: total_training_time_sec 289.47861\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mDeepSpeed-Full-Tune-bs64-bf16-A100\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/optimized-vit-periodic-labs/runs/qmgqttkv\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/siddpath-university-of-maryland/optimized-vit-periodic-labs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251024_203835-qmgqttkv/logs\u001b[0m\n",
            "--- Run complete ---\n",
            "[rank0]:[W1024 20:43:29.664198461 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
            "[2025-10-24 20:43:32,319] [INFO] [launch.py:367:main] Process 14795 exits successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5cra_sOM5y6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pZv-PgHx5y9B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}